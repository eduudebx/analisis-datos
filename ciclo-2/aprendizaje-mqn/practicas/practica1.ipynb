{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<center>\n",
    "    <img src=\"img/logo_ista.png\" height=\"90\">\n",
    "    <b>\n",
    "        <p><font size=\"6\">Instituto Superior Universitario Tecnológico del Azuay</font></p>\n",
    "        <p><font size=\"5\">Tecnología Superior en Big Data</font></p>\n",
    "        <p><font size=\"4\">GUÍA PRÁCTICA N°1</font></p>\n",
    "    </b>\n",
    "    <p><b>Estudiante:</b> Eduardo Mendieta.</p>\n",
    "    <p><b>Docente:</b> Ing. Lady Sangacha.</p>\n",
    "    <p><b>Materia:</b> Aprendizaje de Máquina.</p>\n",
    "    <p><b>Curso:</b> M2A.</p>\n",
    "    \n",
    "</center>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<center>\n",
    "    <p><b><font size=\"5\"><h3>Inteligencia Artificial</font></b></p>\n",
    "    <img src=\"img/p1_ia.jpg\" height=\"90\">\n",
    "</center>\n",
    "\n",
    "<p>La inteligencia artificial es una ciencia que intenta emular el razonamiento y la conducta de los seres humanos a través de modelos de computo avanzados (López, 2017).</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p><b><font size=\"4.5\">Concepto de Machine Learning</font></b></p>\n",
    "\n",
    "<p>El Machine Learnig es una ciencia que a través de algoritmos complejos permite a los computadores aprender de volúmenes grandes de datos sin ser programados explícitamente (Bravo, sf).</p>\n",
    "\n",
    "<p>Bravo (sf), propone un ejemplo en el cual se plantea filtrar correos que son spam. Si lo hicieramos programando linea a linea cada uno de los posibles casos, este llegaría a un punto en el cual sería imposible de mantener. Sin embargo, al usar tecnicas de Machine Learning, el programa aprende de un conjunto de patrones automáticamente y estaría menos propenso a cometer errores.</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p><b><font size=\"4.5\">Tipos de Machine Learning</font></b></p>\n",
    "\n",
    "<center>\n",
    "    <table border=\"1\">\n",
    "        <tr>\n",
    "            <th><strong>Supervisado</strong></th>\n",
    "            <th><strong>No Supervisado</strong></th>\n",
    "            <th><strong>Reforzado</strong></th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>\n",
    "                <p>Los datos de entrenamiento que se pasan al algoritmo como entradas incluyen las salidas esperadas (Bravo, sf). Según Dymaxios Labs (2021), Un evento futuro en base a lo que conocemos del pasado.</p>\n",
    "                <b>Algoritmos:</b>\n",
    "                <ul>\n",
    "                    <li><b>Clasificación:</b>\n",
    "                        Aprender de ejemplos para poder categorizar datos nuevos de manera efectiva(Discretos).\n",
    "                    </li>\n",
    "                    <li><b>Regresión:</b>\n",
    "                        Predecir una variable objetivo numérica a partir de los atributos de un ejemplo.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </td>\n",
    "            <td>\n",
    "                <p>Los datos de entrenamiento no son etiquetados por lo que el sistema trata de aprender de la organización de los mismos (Bravo, sf).</p>\n",
    "                <b>Algoritmos:</b>\n",
    "                <ul>\n",
    "                    <li><b>Clustering:</b>\n",
    "                        Buscar grupos que contengan características similares entre si pero que sean diferentes a los elementos de otros grupos.\n",
    "                    </li>\n",
    "                    <li><b>Reducción:</b>\n",
    "                        Se busca reducir la cantidad de atributos de los datos con el objetivo de simplicar los mismos y evitar que los modelos sean complicados y lentos.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </td>\n",
    "            <td>\n",
    "                Se busca que un \"Agente\" aprenda a tomar decisiones a través de la experiencia. Observando su entorno. Basándose en lo que ve. Recibiendo recompensas cuando ejectuta bien una acción y penalizaciones cuando no lo hace (Bravo, sf).\n",
    "            </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p><b><font size=\"4.5\">Algoritmos de busqueda y motores de búsqueda en Python</font></b></p>\n",
    "\n",
    "<ol>\n",
    "        <li>\n",
    "            <strong>Regresión Logística</strong>\n",
    "            <ul>\n",
    "                <li><strong>Definición:</strong> Modelo estadístico utilizado para predecir la probabilidad de una clase binaria.</li>\n",
    "                <li><strong>Ventajas:</strong> Simple de implementar; fácil de interpretar; eficiente en conjuntos de datos grandes.</li>\n",
    "                <li><strong>Desventajas:</strong> Supone una relación lineal entre variables; no funciona bien con características no lineales.</li>\n",
    "                <li><strong>Función:</strong> Utiliza la función sigmoide para predecir probabilidades.</li>\n",
    "                <li><strong>Algoritmo:</strong> Ajusta coeficientes a través de la maximización de la verosimilitud.</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "        </li>\n",
    "        <li>\n",
    "            <strong>K-Nearest Neighbors (KNN)</strong>\n",
    "            <ul>\n",
    "                <li><strong>Definición:</strong> Algoritmo que clasifica un punto basado en la mayoría de sus k vecinos más cercanos.</li>\n",
    "                <li><strong>Ventajas:</strong> Sencillo y fácil de entender; no requiere suposiciones sobre la distribución de datos.</li>\n",
    "                <li><strong>Desventajas:</strong> Lento en la predicción; sensible a la escala de datos y a la presencia de ruido.</li>\n",
    "                <li><strong>Función:</strong> Clasificación basada en la distancia (euclidiana, Manhattan, etc.).</li>\n",
    "                <li><strong>Algoritmo:</strong> Calcula distancias y asigna la clase más común entre los k vecinos.</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "        </li>\n",
    "        <li>\n",
    "            <strong>Naive Bayes</strong>\n",
    "            <ul>\n",
    "                <li><strong>Definición:</strong> Algoritmo basado en el teorema de Bayes que asume independencia entre características.</li>\n",
    "                <li><strong>Ventajas:</strong> Rápido y eficiente; bueno para grandes conjuntos de datos; funciona bien con datos de texto.</li>\n",
    "                <li><strong>Desventajas:</strong> Supone independencia de características, lo cual no siempre es cierto; puede ser inexacto con correlaciones.</li>\n",
    "                <li><strong>Función:</strong> Calcula probabilidades a partir de la frecuencia de clases.</li>\n",
    "                <li><strong>Algoritmo:</strong> Usa la fórmula de Bayes para estimar la probabilidad de clases.</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "        </li>\n",
    "        <li>\n",
    "            <strong>Árbol de Decisión</strong>\n",
    "            <ul>\n",
    "                <li><strong>Definición:</strong> Modelo que usa una estructura de árbol para tomar decisiones basadas en características de los datos.</li>\n",
    "                <li><strong>Ventajas:</strong> Fácil de interpretar y visualizar; maneja datos no lineales y mixtos.</li>\n",
    "                <li><strong>Desventajas:</strong> Puede sobreajustar los datos; sensible a pequeñas variaciones en los datos.</li>\n",
    "                <li><strong>Función:</strong> Divide los datos en subconjuntos según preguntas sobre características.</li>\n",
    "                <li><strong>Algoritmo:</strong> Utiliza criterios como Gini o entropía para construir el árbol.</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "        </li>\n",
    "        <li>\n",
    "            <strong>Random Forest</strong>\n",
    "            <ul>\n",
    "                <li><strong>Definición:</strong> Conjunto de árboles de decisión que mejora la precisión a través del promedio de múltiples árboles.</li>\n",
    "                <li><strong>Ventajas:</strong> Robusto contra el sobreajuste; maneja bien datos faltantes; proporciona importancia de características.</li>\n",
    "                <li><strong>Desventajas:</strong> Más complejo e interpretativo que un solo árbol; mayor tiempo de computación.</li>\n",
    "                <li><strong>Función:</strong> Clasificación mediante votación de múltiples árboles.</li>\n",
    "                <li><strong>Algoritmo:</strong> Combina múltiples árboles de decisión a partir de muestreo aleatorio.</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "        </li>\n",
    "        <li>\n",
    "            <strong>XGBoost</strong>\n",
    "            <ul>\n",
    "                <li><strong>Definición:</strong> Algoritmo de boosting que mejora la precisión mediante la construcción secuencial de árboles.</li>\n",
    "                <li><strong>Ventajas:</strong> Alta precisión; velocidad y eficiencia; maneja datos grandes y faltantes.</li>\n",
    "                <li><strong>Desventajas:</strong> Más complejo de entender; puede ser propenso al sobreajuste sin regularización.</li>\n",
    "                <li><strong>Función:</strong> Predicción basada en la combinación de varios modelos de árboles.</li>\n",
    "                <li><strong>Algoritmo:</strong> Optimiza la función de pérdida utilizando técnicas de gradient boosting.</li>\n",
    "                <br>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            <strong>LightGBM</strong>\n",
    "            <ul>\n",
    "                <li><strong>Definición:</strong> Versión optimizada de XGBoost que utiliza un enfoque de aprendizaje basado en histogramas.</li>\n",
    "                <li><strong>Ventajas:</strong> Rápido y eficiente en memoria; maneja grandes volúmenes de datos.</li>\n",
    "                <li><strong>Desventajas:</strong> Puede ser complicado de ajustar; sensibilidad a hiperparámetros.</li>\n",
    "                <li><strong>Función:</strong> Clasificación y regresión a través de árboles de decisión en histogramas.</li>\n",
    "                <li><strong>Algoritmo:</strong> Construye árboles utilizando el enfoque de gradient boosting con histogramas.</li>\n",
    "                <br>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ol>\n",
    "<br>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo KNN: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # Para manejar arrays y operaciones numéricas\n",
    "from sklearn.datasets import make_classification  # Para generar un conjunto de datos de clasificación\n",
    "from sklearn.model_selection import train_test_split  # Para dividir los datos en conjuntos de entrenamiento y prueba\n",
    "from sklearn.neighbors import KNeighborsClassifier  # Para el algoritmo KNN\n",
    "from sklearn.metrics import accuracy_score  # Para medir la precisión del modelo\n",
    "\n",
    "# Generar un conjunto de datos sintético\n",
    "# make_classification crea un conjunto de datos de clasificación\n",
    "caracteristicas, etiquetas = make_classification(n_samples=100,  # Número total de muestras\n",
    "                                                n_features=2,  # Número de características \n",
    "                                                n_informative=2,  # Número de características informativas\n",
    "                                                n_redundant=0,  # Número de características redundantes\n",
    "                                                n_clusters_per_class=1,  # Número de clusters por clase\n",
    "                                                random_state=42)  # Para reproducibilidad\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "caracteristicas_entrenamiento, caracteristicas_prueba, etiquetas_entrenamiento, etiquetas_prueba = train_test_split(\n",
    "    caracteristicas, etiquetas,  # Datos y etiquetas\n",
    "    test_size=0.2,  # 20% de los datos para prueba\n",
    "    random_state=42)  # Para reproducibilidad\n",
    "\n",
    "# Crear el clasificador KNN con k=3 (3 vecinos más cercanos)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Entrenar el clasificador con los datos de entrenamiento\n",
    "knn.fit(caracteristicas_entrenamiento, etiquetas_entrenamiento)\n",
    "\n",
    "# Hacer predicciones con los datos de prueba\n",
    "etiquetas_predicciones = knn.predict(caracteristicas_prueba)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "precision = accuracy_score(etiquetas_prueba, etiquetas_predicciones)\n",
    "\n",
    "# Imprimir la precisión\n",
    "print(f'Precisión del modelo KNN: {precision:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión de 1.00 entregado por el modelo significa que este ha clasificado correctamente todas las instancias en el conjunto de prueba."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ista",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
